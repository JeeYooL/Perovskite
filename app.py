import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import io
import re

from sklearn.model_selection import train_test_split, KFold, GridSearchCV, cross_val_score
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_absolute_error

# -------------------------------------------------------------------
# í˜ì´ì§€ ì„¤ì •
# -------------------------------------------------------------------
st.set_page_config(
    page_title="Perovskite ML Optimizer V2.0",
    page_icon="âš—ï¸",
    layout="wide"
)

# ìŠ¤íƒ€ì¼ ì»¤ìŠ¤í…€
st.markdown("""
    <style>
    .main {
        background-color: #f8f9fa;
    }
    h1 {
        color: #2c3e50;
    }
    .stButton>button {
        width: 100%;
        background-color: #4CAF50;
        color: white;
    }
    </style>
""", unsafe_allow_html=True)

# -------------------------------------------------------------------
# í•¨ìˆ˜ ì •ì˜
# -------------------------------------------------------------------

def load_data(uploaded_files):
    """ì—…ë¡œë“œëœ íŒŒì¼ë“¤ì„ í•˜ë‚˜ì˜ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³‘í•©"""
    all_dfs = []
    for uploaded_file in uploaded_files:
        try:
            if uploaded_file.name.endswith('.csv'):
                df = pd.read_csv(uploaded_file)
                all_dfs.append(df)
            elif uploaded_file.name.endswith('.xlsx'):
                df = pd.read_excel(uploaded_file)
                all_dfs.append(df)
        except Exception as e:
            st.error(f"íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({uploaded_file.name}): {e}")
    
    if all_dfs:
        return pd.concat(all_dfs, ignore_index=True)
    return None

def preprocess_data(df):
    """ë°ì´í„° ì „ì²˜ë¦¬: ê²°ì¸¡ì¹˜ ì œê±°, íƒ€ê²Ÿ ë¶„ë¦¬, MLB(Multi-Label Binarization)"""
    target_column = 'PCE (%)'
    
    # íƒ€ê²Ÿ ê°’ì´ ì—†ëŠ” í–‰ ì œê±°
    if target_column not in df.columns:
        st.error(f"ë°ì´í„°ì— '{target_column}' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None, None, None, None

    df_cleaned = df.dropna(subset=[target_column]).copy()
    
    # Data Leakage ë°©ì§€ë¥¼ ìœ„í•œ ê²°ê³¼ê°’ ì»¬ëŸ¼ ì œì™¸
    drop_cols = [
        'PCE (%)', 'Voc (V)', 'Jsc (mA/cm2)', 'FF (%)', 'Rs (Î©Â·cmÂ²)', 'Rsh (Î©Â·cmÂ²)',
        'Sample', 'File', 'Scan Direction', 'Unnamed: 0'
    ]
    # ì‹¤ì œ ë°ì´í„°ì…‹ì— ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ drop
    cols_to_drop = [c for c in drop_cols if c in df_cleaned.columns]
    
    X_raw = df_cleaned.drop(columns=cols_to_drop, errors='ignore')
    y = df_cleaned[target_column]
    
    # ë¬¸ìì—´/ìˆ˜ì¹˜í˜• ë¶„ë¦¬
    X_numeric = X_raw.select_dtypes(exclude=['object'])
    X_categorical = X_raw.select_dtypes(include=['object'])
    
    # ë²”ì£¼í˜• ë°ì´í„° ì²˜ë¦¬ (MLB ë°©ì‹: 'A + B' -> A, B ê°ê° 1)
    all_processed_dfs = [X_numeric]
    
    # ì „ì²˜ë¦¬ ê³¼ì • ë¡œê·¸ìš©
    processed_cols_log = []

    for col in X_categorical.columns:
        # ê²°ì¸¡ì¹˜ëŠ” ë¹ˆ ë¬¸ìì—´ë¡œ ì²˜ë¦¬ í›„ ë¶„ë¦¬
        binarized = X_categorical[col].fillna('').astype(str).str.get_dummies(sep=' + ')
        
        # ì»¬ëŸ¼ëª…ì— ì›ë˜ ë³€ìˆ˜ëª… ì ‘ë‘ì‚¬ ì¶”ê°€ (ì˜ˆ: Solvent_DMF)
        binarized = binarized.add_prefix(f"{col}_")
        
        # íŠ¹ìˆ˜ë¬¸ì ì •ì œ (ì»¬ëŸ¼ëª… ê¹¨ì§ ë°©ì§€)
        binarized.columns = binarized.columns.str.replace(r'[^\w\s]', '_', regex=True).str.replace(r'\s+', '_', regex=True)
        
        all_processed_dfs.append(binarized)
        processed_cols_log.append(col)
        
    X_processed = pd.concat(all_processed_dfs, axis=1).fillna(0)
    
    return X_processed, y, df_cleaned, X_raw

# -------------------------------------------------------------------
# UI êµ¬ì„±
# -------------------------------------------------------------------

st.title("âš—ï¸ Perovskite ê³µì • ìµœì í™” ë° ì„±ëŠ¥ ì˜ˆì¸¡ AI (V2.0)")
st.markdown("---")

# ì‚¬ì´ë“œë°”: ë°ì´í„° ì—…ë¡œë“œ ë° ì„¤ì •
with st.sidebar:
    st.header("1. ë°ì´í„° ì—…ë¡œë“œ")
    uploaded_files = st.file_uploader(
        "CSV ë˜ëŠ” Excel íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)", 
        type=['csv', 'xlsx'], 
        accept_multiple_files=True
    )
    
    st.markdown("---")
    st.header("2. ëª¨ë¸ ì„¤ì •")
    test_size = st.slider("í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¹„ìœ¨", 0.1, 0.4, 0.2, 0.05)
    cv_folds = st.slider("êµì°¨ ê²€ì¦ (K-Fold) íšŸìˆ˜", 2, 10, 5)
    
    st.markdown("---")
    st.info("ğŸ’¡ **Tip**: 'A + B' í˜•íƒœì˜ í…ìŠ¤íŠ¸ ë°ì´í„°ëŠ” ìë™ìœ¼ë¡œ ë¶„ë¦¬ë˜ì–´ í•™ìŠµë©ë‹ˆë‹¤.")

if uploaded_files:
    # 1. ë°ì´í„° ë¡œë“œ
    raw_df = load_data(uploaded_files)
    
    if raw_df is not None:
        st.write(f"âœ… ì´ **{len(raw_df)}**ê°œì˜ ìƒ˜í”Œì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
        with st.expander("ì›ë³¸ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°"):
            st.dataframe(raw_df.head())

        # 2. ì „ì²˜ë¦¬ ë° í•™ìŠµ ë²„íŠ¼
        if st.button("ğŸš€ AI ëª¨ë¸ í•™ìŠµ ë° ìµœì í™” ì‹œì‘"):
            with st.spinner('ë°ì´í„° ì „ì²˜ë¦¬ ë° ëª¨ë¸ ìµœì í™” ì¤‘ì…ë‹ˆë‹¤... (ì‹œê°„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤)'):
                
                # ì „ì²˜ë¦¬ ì‹¤í–‰
                X, y, df_clean, X_raw_origin = preprocess_data(raw_df)
                
                if X is not None:
                    st.success(f"ì „ì²˜ë¦¬ ì™„ë£Œ! í•™ìŠµì— ì‚¬ìš©ë  í”¼ì²˜ ìˆ˜: **{X.shape[1]}ê°œ**")
                    
                    # 3. ë°ì´í„° ë¶„í• 
                    X_train, X_test, y_train, y_test = train_test_split(
                        X, y, test_size=test_size, random_state=42
                    )
                    
                    # 4. GridSearchCV (í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹)
                    param_grid = {
                        'n_estimators': [100, 200, 300],
                        'max_depth': [None, 10, 20],
                        'min_samples_split': [2, 5]
                    }
                    
                    rf = RandomForestRegressor(random_state=42, n_jobs=-1)
                    grid_search = GridSearchCV(
                        rf, 
                        param_grid, 
                        cv=cv_folds, 
                        scoring='neg_mean_absolute_error',
                        verbose=0
                    )
                    
                    grid_search.fit(X_train, y_train)
                    best_model = grid_search.best_estimator_
                    
                    st.markdown("---")
                    
                    # 5. ê²°ê³¼ ë¦¬í¬íŠ¸ ì„¹ì…˜ (2ë‹¨ ë ˆì´ì•„ì›ƒ)
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.subheader("ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ í‰ê°€")
                        
                        # êµì°¨ ê²€ì¦ ì ìˆ˜
                        cv_scores = cross_val_score(best_model, X, y, cv=cv_folds, scoring='r2')
                        st.metric("5-Fold CV í‰ê·  RÂ²", f"{cv_scores.mean():.4f}")
                        
                        # í…ŒìŠ¤íŠ¸ ì…‹ ì ìˆ˜
                        y_pred = best_model.predict(X_test)
                        r2 = r2_score(y_test, y_pred)
                        mae = mean_absolute_error(y_test, y_pred)
                        
                        st.write(f"**í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ RÂ²:** {r2:.4f}")
                        st.write(f"**í‰ê·  ì˜¤ì°¨ (MAE):** {mae:.4f} %PCE")
                        st.caption(f"ìµœì  íŒŒë¼ë¯¸í„°: {grid_search.best_params_}")
                        
                        # ì‹¤ì œê°’ vs ì˜ˆì¸¡ê°’ ê·¸ë˜í”„
                        fig, ax = plt.subplots(figsize=(6, 5))
                        ax.scatter(y_test, y_pred, alpha=0.6, edgecolors='w', color='#2980b9')
                        ax.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2)
                        ax.set_xlabel("Actual PCE (%)")
                        ax.set_ylabel("Predicted PCE (%)")
                        ax.set_title("Actual vs Predicted")
                        ax.grid(True, alpha=0.3)
                        st.pyplot(fig)

                    with col2:
                        st.subheader("ğŸ”‘ ì¤‘ìš” ê³µì • ë³€ìˆ˜ (Top 20)")
                        
                        # ì¤‘ìš”ë„ ì¶”ì¶œ
                        importances = best_model.feature_importances_
                        feat_imp_df = pd.DataFrame({'Feature': X.columns, 'Importance': importances})
                        feat_imp_df = feat_imp_df.sort_values(by='Importance', ascending=False).head(20)
                        
                        # ì¤‘ìš”ë„ ê·¸ë˜í”„
                        fig2, ax2 = plt.subplots(figsize=(6, 8))
                        sns.barplot(x='Importance', y='Feature', data=feat_imp_df, palette='viridis', ax=ax2)
                        ax2.set_title("Feature Importance")
                        st.pyplot(fig2)

                    st.markdown("---")
                    
                    # 6. ì‹¤í—˜ ë°©í–¥ ì œì•ˆ
                    st.header("ğŸ’¡ AI ê¸°ë°˜ ì‹¤í—˜ ì œì•ˆ")
                    st.write("í˜„ì¬ ë°ì´í„°ì…‹ ë‚´ **ìµœê³  íš¨ìœ¨ ì¥ì¹˜**ì˜ ë ˆì‹œí”¼ì™€ **ì¤‘ìš” ë³€ìˆ˜**ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„í•œ ê²°ê³¼ì…ë‹ˆë‹¤.")
                    
                    best_idx = y.idxmax()
                    best_val = y.max()
                    
                    st.success(f"ğŸ† í˜„ì¬ ìµœê³  íš¨ìœ¨: **{best_val:.2f}%** (Sample ID: {best_idx})")
                    
                    # ìµœê³  íš¨ìœ¨ ë ˆì‹œí”¼ ì¶”ì¶œ
                    best_recipe = df_clean.loc[best_idx]
                    
                    # ì¤‘ìš” ë³€ìˆ˜ ìƒìœ„ 5ê°œì— ëŒ€í•œ ì œì•ˆ ìƒì„±
                    suggestions = []
                    for feat in feat_imp_df['Feature'].head(5):
                        # ì›ë³¸ ì»¬ëŸ¼ ì°¾ê¸° (MLB ì „ì˜ ì´ë¦„ ì¶”ì )
                        # ì˜ˆ: Solvent_DMF -> Solvent
                        original_col = next((c for c in X_raw_origin.columns if feat.startswith(c)), None)
                        
                        if original_col:
                            val = best_recipe.get(original_col, "N/A")
                            suggestions.append({
                                "ì¤‘ìš” ë³€ìˆ˜ (Feature)": feat,
                                "ì›ì¸ ë³€ìˆ˜": original_col,
                                "ìµœê³  íš¨ìœ¨ ì¡°ê±´ ê°’": val,
                                "ì œì•ˆ": "ì´ ë³€ìˆ˜ëŠ” ì„±ëŠ¥ì— ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤. ìœ„ ê°’ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë¯¸ì„¸ ì¡°ì •(Fine-tuning) í•˜ì„¸ìš”."
                            })
                        else:
                            # ìˆ˜ì¹˜í˜• ë³€ìˆ˜ì¼ ê²½ìš°
                            val = best_recipe.get(feat, "N/A")
                            suggestions.append({
                                "ì¤‘ìš” ë³€ìˆ˜ (Feature)": feat,
                                "ì›ì¸ ë³€ìˆ˜": feat,
                                "ìµœê³  íš¨ìœ¨ ì¡°ê±´ ê°’": val,
                                "ì œì•ˆ": "ìˆ˜ì¹˜í˜• ì¤‘ìš” ë³€ìˆ˜ì…ë‹ˆë‹¤. ì´ ê°’ ì£¼ë³€ìœ¼ë¡œ ë²”ìœ„ë¥¼ ì¢í˜€ ìµœì í™”í•˜ì„¸ìš”."
                            })
                    
                    st.table(pd.DataFrame(suggestions))

else:
    st.info("ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ë°ì´í„° íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
    st.markdown("""
    ### ğŸ‘‹ í™˜ì˜í•©ë‹ˆë‹¤!
    ì´ ì•±ì€ í˜ë¡œë¸ŒìŠ¤ì¹´ì´íŠ¸ íƒœì–‘ì „ì§€ ê³µì • ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ìµœì ì˜ ë ˆì‹œí”¼ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.
    
    **ë°ì´í„° íŒŒì¼ í˜•ì‹:**
    - `.csv` ë˜ëŠ” `.xlsx`
    - í•„ìˆ˜ ì»¬ëŸ¼: `PCE (%)`
    - ê·¸ ì™¸ ê³µì • ë³€ìˆ˜ë“¤ (ì˜ˆ: `Temp`, `Solvent`, `Additive` ë“±)
    """)
