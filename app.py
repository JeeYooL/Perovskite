import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import io
import re

# ë¨¸ì‹ ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬
from sklearn.model_selection import train_test_split, KFold, GridSearchCV, cross_val_score
from sklearn.metrics import r2_score, mean_absolute_error
from sklearn.preprocessing import StandardScaler

# ëª¨ë¸
import xgboost as xgb
from sklearn.ensemble import RandomForestRegressor
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import Matern, RBF, ConstantKernel, WhiteKernel

# ì„¤ëª… ê°€ëŠ¥í•œ AI
import shap

# -------------------------------------------------------------------
# í˜ì´ì§€ ì„¤ì •
# -------------------------------------------------------------------
st.set_page_config(
    page_title="Perovskite AI Lab V5",
    page_icon="ğŸ§ª",
    layout="wide"
)

st.markdown("""
    <style>
    .main { background-color: #ffffff; }
    h1, h2, h3 { color: #003366; font-family: 'Arial', sans-serif; }
    .stMetric { background-color: #f8f9fa; padding: 15px; border-radius: 8px; border: 1px solid #e9ecef; }
    .stAlert { padding: 10px; border-radius: 5px; }
    </style>
""", unsafe_allow_html=True)

# -------------------------------------------------------------------
# í•¨ìˆ˜ ì •ì˜
# -------------------------------------------------------------------

def load_data(uploaded_files):
    """íŒŒì¼ ë¡œë“œ ë° ë³‘í•©"""
    all_dfs = []
    for uploaded_file in uploaded_files:
        try:
            if uploaded_file.name.endswith('.csv'):
                try:
                    df = pd.read_csv(uploaded_file, encoding='utf-8')
                except UnicodeDecodeError:
                    df = pd.read_csv(uploaded_file, encoding='cp949')
                all_dfs.append(df)
            elif uploaded_file.name.endswith('.xlsx'):
                df = pd.read_excel(uploaded_file)
                all_dfs.append(df)
        except Exception as e:
            st.error(f"íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜ ({uploaded_file.name}): {e}")
    
    if all_dfs:
        return pd.concat(all_dfs, ignore_index=True)
    return None

def clean_column_names(df):
    """ì»¬ëŸ¼ëª… íŠ¹ìˆ˜ë¬¸ì ì œê±° (XGBoost ë“± í˜¸í™˜ì„± í™•ë³´)"""
    df.columns = df.columns.str.strip()
    return df

def detect_target_column(df):
    """íƒ€ê²Ÿ ì»¬ëŸ¼(PCE) ìë™ ê°ì§€"""
    candidates = [c for c in df.columns if 'PCE' in c.upper()]
    if candidates:
        return candidates[0]
    return df.columns[-1] if not df.empty else None

def preprocess_data(df, target_column):
    """ì „ì²˜ë¦¬: íƒ€ê²Ÿ ë¶„ë¦¬, ê²°ì¸¡ì¹˜ ì œê±°, ì¸ì½”ë”©, í˜•ë³€í™˜"""
    
    # 1. íƒ€ê²Ÿê°’ ê²°ì¸¡ì¹˜ ì œê±°
    df_cleaned = df.dropna(subset=[target_column]).copy()
    
    if len(df_cleaned) == 0:
        return None, None, None, None

    # 2. ê²°ê³¼ ì§€í‘œ ì œê±° (Data Leakage ë°©ì§€)
    drop_keywords = ['PCE', 'Voc', 'Jsc', 'FF', 'Rs', 'Rsh', 'Scan', 'Sample', 'File', 'Unnamed']
    cols_to_drop = []
    for col in df_cleaned.columns:
        if col == target_column: continue
        for kw in drop_keywords:
            if kw in col:
                cols_to_drop.append(col)
                break
    
    X_raw = df_cleaned.drop(columns=cols_to_drop, errors='ignore')
    y = df_cleaned[target_column]
    
    # 3. MLB / One-Hot Encoding
    X_numeric = X_raw.select_dtypes(exclude=['object'])
    X_categorical = X_raw.select_dtypes(include=['object'])
    
    all_processed = [X_numeric]
    for col in X_categorical.columns:
        # 'A + B' í˜•íƒœ ë¶„ë¦¬
        binarized = X_categorical[col].fillna('').astype(str).str.get_dummies(sep=' + ')
        binarized = binarized.add_prefix(f"{col}_")
        all_processed.append(binarized)
        
    X_processed = pd.concat(all_processed, axis=1).fillna(0)
    
    # 4. íŠ¹ìˆ˜ë¬¸ì ì œê±° (ì»¬ëŸ¼ëª…)
    X_processed.columns = X_processed.columns.str.replace(r'[^\w\s]', '_', regex=True).str.replace(r'\s+', '_', regex=True)
    
    # 5. [ì¤‘ìš”] ëª¨ë“  ë°ì´í„°ë¥¼ floatí˜•ìœ¼ë¡œ ê°•ì œ ë³€í™˜ (ì—ëŸ¬ ë°©ì§€)
    try:
        X_processed = X_processed.astype(float)
    except ValueError:
        # ë³€í™˜ ì‹¤íŒ¨ ì‹œ (í˜¹ì‹œ ëª¨ë¥¼ ë¬¸ìì—´ ì”ì¬) ê°•ì œ ë³€í™˜
        for col in X_processed.columns:
            X_processed[col] = pd.to_numeric(X_processed[col], errors='coerce').fillna(0)

    return X_processed, y, df_cleaned, X_raw

# -------------------------------------------------------------------
# ë©”ì¸ UI
# -------------------------------------------------------------------

st.title("ğŸ§ª Perovskite AI Lab V5")
st.write("ì¬ë£Œ íƒìƒ‰ ë° ê³µì • ìµœì í™”ë¥¼ ìœ„í•œ ì§€ëŠ¥í˜• ë¶„ì„ í”Œë«í¼")
st.markdown("---")

# 1. ì‚¬ì´ë“œë°”: ë°ì´í„° ì—…ë¡œë“œ
with st.sidebar:
    st.header("ğŸ“‚ 1. Data Input")
    uploaded_files = st.file_uploader("CSV/Excel ì—…ë¡œë“œ", type=['csv', 'xlsx'], accept_multiple_files=True)
    
    st.markdown("---")
    st.caption("Developed based on recent PV ML studies (Nature Energy, 2024)")

if uploaded_files:
    raw_df = load_data(uploaded_files)
    
    if raw_df is not None:
        raw_df = clean_column_names(raw_df)
        st.write(f"âœ… **{len(raw_df)}**ê°œì˜ ìƒ˜í”Œ ë°ì´í„°ê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        with st.expander("ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°"):
            st.dataframe(raw_df.head())
        
        st.markdown("---")
        
        # ----------------------------------------------------------------
        # 2. ì‚¬ìš©ì ì„¤ì • (íƒ€ê²Ÿ & ëª¨ë¸ ì„ íƒ)
        # ----------------------------------------------------------------
        st.header("âš™ï¸ 2. Analysis Settings")
        
        col_set1, col_set2, col_set3 = st.columns(3)
        
        # Step 1: íƒ€ê²Ÿ ë³€ìˆ˜ ì„ íƒ
        with col_set1:
            default_target = detect_target_column(raw_df)
            try:
                default_idx = list(raw_df.columns).index(default_target) if default_target else 0
            except:
                default_idx = 0
                
            target_col = st.selectbox(
                "ëª©í‘œ íƒ€ê²Ÿ (Target Variable)", 
                options=raw_df.columns, 
                index=default_idx,
                help="ì˜ˆì¸¡í•˜ê³ ì í•˜ëŠ” ê°’ (ë³´í†µ íš¨ìœ¨ PCE)"
            )

        # Step 2: ëª¨ë¸ ì„ íƒ
        with col_set2:
            model_options = [
                "XGBoost (Recommended)",
                "Random Forest (Robust)",
                "Gaussian Process (Bayesian Opt.)"
            ]
            model_choice = st.selectbox(
                "ì‚¬ìš©í•  ML ëª¨ë¸", 
                options=model_options,
                help="ë°ì´í„°ê°€ ì ë‹¤ë©´ Gaussian Processë‚˜ Random Forestë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤."
            )
        
        # Step 3: í…ŒìŠ¤íŠ¸ ë¹„ìœ¨
        with col_set3:
            test_ratio = st.slider("í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¹„ìœ¨", 0.1, 0.5, 0.2, 0.05)

        # ê²½ê³  ë° ê°€ì´ë“œ ë©”ì‹œì§€
        data_len = len(raw_df)
        if data_len < 20:
            st.warning(f"âš ï¸ ë°ì´í„°ê°€ **{data_len}ê°œ**ë¡œ ë§¤ìš° ì ìŠµë‹ˆë‹¤.")
            if "XGBoost" in model_choice:
                st.error("ğŸ›‘ XGBoostëŠ” ë°ì´í„°ê°€ ë„ˆë¬´ ì ì„ ë•Œ(20ê°œ ë¯¸ë§Œ) ì‘ë™í•˜ì§€ ì•Šê±°ë‚˜ ê³¼ì í•©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. **Gaussian Process** ë˜ëŠ” **Random Forest**ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
            else:
                st.info("ğŸ’¡ ì ì€ ë°ì´í„°ì…‹(Small Data)ì— ê°•í•œ ëª¨ë¸ì„ ì„ íƒí•˜ì…¨êµ°ìš”. ë¶„ì„ì„ ì§„í–‰í•©ë‹ˆë‹¤.")

        # ----------------------------------------------------------------
        # 3. ë¶„ì„ ì‹¤í–‰
        # ----------------------------------------------------------------
        st.markdown("<br>", unsafe_allow_html=True)
        if st.button("ğŸš€ AI ë¶„ì„ ë° ìµœì í™” ì‹œì‘ (Run Analysis)", type="primary"):
            
            # ëª¨ë¸ ì‹¤í–‰ ì¡°ê±´ ì²´í¬ (ë°ì´í„° ë„ˆë¬´ ì ê³  XGBoostë©´ ì¤‘ë‹¨ ê°€ëŠ¥í•˜ë‚˜, ì¼ë‹¨ ì§„í–‰í•˜ë˜ try-catch)
            with st.spinner(f"ë°ì´í„° ì „ì²˜ë¦¬ ë° {model_choice.split()[0]} ìµœì í™” ì¤‘..."):
                
                # ì „ì²˜ë¦¬
                X, y, df_clean, X_raw_origin = preprocess_data(raw_df, target_col)
                
                if X is None:
                    st.error("ì „ì²˜ë¦¬ ì‹¤íŒ¨: íƒ€ê²Ÿ ì»¬ëŸ¼ì— ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    # ë°ì´í„° ë¶„í• 
                    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_ratio, random_state=42)
                    
                    # ëª¨ë¸ ì´ˆê¸°í™” ë° í•™ìŠµ
                    model = None
                    is_tree_model = False
                    
                    try:
                        # -----------------------
                        # A. XGBoost
                        # -----------------------
                        if "XGBoost" in model_choice:
                            is_tree_model = True
                            xgb_reg = xgb.XGBRegressor(objective='reg:squarederror', n_jobs=-1, random_state=42)
                            param_grid = {
                                'n_estimators': [100, 200] if len(X) < 50 else [100, 300, 500],
                                'max_depth': [3, 5],
                                'learning_rate': [0.05, 0.1]
                            }
                            search = GridSearchCV(xgb_reg, param_grid, cv=3, scoring='neg_mean_absolute_error')
                            search.fit(X_train, y_train)
                            model = search.best_estimator_
                            st.caption(f"Best Params: {search.best_params_}")

                        # -----------------------
                        # B. Random Forest
                        # -----------------------
                        elif "Random Forest" in model_choice:
                            is_tree_model = True
                            rf_reg = RandomForestRegressor(random_state=42, n_jobs=-1)
                            param_grid = {
                                'n_estimators': [100, 200],
                                'max_depth': [None, 10],
                                'min_samples_leaf': [1, 2]
                            }
                            search = GridSearchCV(rf_reg, param_grid, cv=3, scoring='neg_mean_absolute_error')
                            search.fit(X_train, y_train)
                            model = search.best_estimator_
                            st.caption(f"Best Params: {search.best_params_}")

                        # -----------------------
                        # C. Gaussian Process (Bayesian Opt Logic)
                        # -----------------------
                        elif "Gaussian Process" in model_choice:
                            # ë°ì´í„° ìŠ¤ì¼€ì¼ë§ (GPëŠ” ìŠ¤ì¼€ì¼ì— ë¯¼ê°)
                            scaler_X = StandardScaler()
                            X_train_scaled = scaler_X.fit_transform(X_train)
                            X_test_scaled = scaler_X.transform(X_test)
                            
                            # ì»¤ë„ ì •ì˜ (RBF + WhiteKernel for noise)
                            kernel = 1.0 * RBF(length_scale=1.0) + WhiteKernel(noise_level=1.0)
                            gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=5, random_state=42)
                            gp.fit(X_train_scaled, y_train)
                            model = gp
                            
                            # ì˜ˆì¸¡ í•¨ìˆ˜ ì˜¤ë²„ë¼ì´ë”© (ìŠ¤ì¼€ì¼ë§ í¬í•¨)
                            def gp_predict(X_input):
                                X_input_scaled = scaler_X.transform(X_input)
                                return gp.predict(X_input_scaled, return_std=False)
                            
                            model.predict = gp_predict # ë• íƒ€ì´í•‘
                            
                            # GPëŠ” Test set ì˜ˆì¸¡ ì‹œ stdë„ ë°˜í™˜ë°›ì•„ì„œ ë¶ˆí™•ì‹¤ì„± ì‹œê°í™” ê°€ëŠ¥
                            y_pred, y_std = gp.predict(X_test_scaled, return_std=True)

                        # ê³µí†µ ì˜ˆì¸¡ ë° í‰ê°€
                        if "Gaussian Process" not in model_choice:
                            y_pred = model.predict(X_test)
                        
                        r2 = r2_score(y_test, y_pred)
                        mae = mean_absolute_error(y_test, y_pred)
                        
                        # ----------------------------------------------------------------
                        # 4. ê²°ê³¼ ë¦¬í¬íŠ¸
                        # ----------------------------------------------------------------
                        st.success("âœ… ë¶„ì„ ì™„ë£Œ!")
                        
                        # Tab êµ¬ì„±
                        tab1, tab2, tab3 = st.tabs(["ğŸ“Š ì„±ëŠ¥ í‰ê°€", "ğŸ” ì¤‘ìš”ë„ ë¶„ì„ (XAI)", "ğŸ’¡ ìµœì í™” ì œì•ˆ"])
                        
                        with tab1:
                            c1, c2 = st.columns(2)
                            c1.metric("RÂ² Score (ì •í™•ë„)", f"{r2:.4f}")
                            c2.metric("MAE (í‰ê·  ì˜¤ì°¨)", f"{mae:.4f}")
                            
                            fig, ax = plt.subplots(figsize=(6, 5))
                            ax.scatter(y_test, y_pred, alpha=0.7, edgecolors='k', label='Data')
                            ax.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2, label='Ideal')
                            if "Gaussian Process" in model_choice:
                                ax.errorbar(y_test, y_pred, yerr=y_std, fmt='none', alpha=0.2, ecolor='gray', label='Uncertainty')
                            
                            ax.set_xlabel(f"Actual {target_col}")
                            ax.set_ylabel(f"Predicted {target_col}")
                            ax.set_title(f"{model_choice.split()[0]} Regression Result")
                            ax.legend()
                            st.pyplot(fig)

                        with tab2:
                            st.subheader("Feature Analysis")
                            if is_tree_model:
                                st.write("**SHAP (SHapley Additive exPlanations)** ë¶„ì„ ê²°ê³¼")
                                explainer = shap.Explainer(model, X_train)
                                shap_values = explainer(X_test)
                                
                                fig_shap, ax_shap = plt.subplots()
                                shap.summary_plot(shap_values, X_test, show=False)
                                st.pyplot(fig_shap)
                                
                                # ì¤‘ìš”ë„ ì¶”ì¶œ
                                importances = np.abs(shap_values.values).mean(axis=0)
                            else:
                                st.info("Gaussian ProcessëŠ” SHAP ëŒ€ì‹  ARD(Automatic Relevance Determination) ë˜ëŠ” ìƒê´€ê³„ìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¤‘ìš”ë„ë¥¼ ì¶”ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (í˜„ì¬ ë²„ì „ì€ ìƒê´€ê³„ìˆ˜ í‘œì‹œ)")
                                # ê°„ë‹¨í•œ ìƒê´€ê³„ìˆ˜ íˆíŠ¸ë§µ
                                corr = X.copy()
                                corr['Target'] = y
                                corr_matrix = corr.corr()[['Target']].sort_values(by='Target', key=abs, ascending=False).head(10)
                                st.dataframe(corr_matrix.style.background_gradient(cmap='coolwarm'))
                                importances = np.abs(corr.corr()[target_col].drop(target_col).values)

                        with tab3:
                            st.subheader("ì‹¤í—˜ ì¡°ê±´ ìµœì í™” ì œì•ˆ")
                            best_idx = y.idxmax()
                            st.success(f"í˜„ì¬ ìµœê³  ì„±ëŠ¥: **{y.max():.4f}** (Sample ID: {best_idx})")
                            
                            # ì¤‘ìš” ë³€ìˆ˜ Top 5
                            if is_tree_model:
                                feat_imp_df = pd.DataFrame({'Feature': X.columns, 'Imp': importances})
                            else:
                                feat_imp_df = pd.DataFrame({'Feature': X.columns, 'Imp': list(importances)[:len(X.columns)]}) # ë‹¨ìˆœ ë§¤í•‘
                                
                            top_feats = feat_imp_df.sort_values('Imp', ascending=False).head(5)['Feature'].tolist()
                            
                            best_recipe = df_clean.loc[best_idx]
                            suggestions = []
                            for feat in top_feats:
                                # ì›ë³¸ ì»¬ëŸ¼ ì°¾ê¸°
                                orig = feat
                                for raw_c in X_raw_origin.columns:
                                    # ì „ì²˜ë¦¬ëœ ì´ë¦„ê³¼ ë§¤ì¹­ë˜ëŠ”ì§€ í™•ì¸ (ë‹¨ìˆœ í¬í•¨ ê´€ê³„)
                                    if re.sub(r'[^\w]', '_', str(raw_c)) in feat:
                                        orig = raw_c
                                        break
                                
                                val = best_recipe.get(orig, best_recipe.get(feat, "N/A"))
                                suggestions.append({
                                    "ì¤‘ìš” ë³€ìˆ˜": feat,
                                    "í˜„ì¬ ìµœê³ ê°’": val,
                                    "ì œì•ˆ": "ì´ ë³€ìˆ˜ì˜ ì£¼ë³€ ê°’ì„ íƒìƒ‰(Exploration) í•˜ì„¸ìš”."
                                })
                            
                            st.table(pd.DataFrame(suggestions))
                            
                    except Exception as e:
                        st.error(f"ëª¨ë¸ í•™ìŠµ ì¤‘ ì¹˜ëª…ì ì¸ ì˜¤ë¥˜ ë°œìƒ: {e}")
                        st.write("í•´ê²°ì±…: ë°ì´í„° ìƒ˜í”Œ ìˆ˜ë¥¼ ëŠ˜ë¦¬ê±°ë‚˜, ë²”ì£¼í˜• ë³€ìˆ˜ì˜ ì¢…ë¥˜ë¥¼ ì¤„ì—¬ë³´ì„¸ìš”.")

else:
    st.info("ğŸ‘ˆ ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ë°ì´í„° íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
