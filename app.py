import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import io
import re

# ë¨¸ì‹ ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬
from sklearn.model_selection import train_test_split, KFold, GridSearchCV, cross_val_score
from sklearn.metrics import r2_score, mean_absolute_error
from sklearn.preprocessing import StandardScaler

# ëª¨ë¸
import xgboost as xgb
from sklearn.ensemble import RandomForestRegressor
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import Matern, RBF, ConstantKernel, WhiteKernel

# ì„¤ëª… ê°€ëŠ¥í•œ AI
import shap

# -------------------------------------------------------------------
# í˜ì´ì§€ ì„¤ì •
# -------------------------------------------------------------------
st.set_page_config(
    page_title="Perovskite AI Lab V5",
    page_icon="ğŸ§ª",
    layout="wide"
)

# UI ìŠ¤íƒ€ì¼ ê°œì„  (ìŠ¤í¬ë¡¤ ë° ì—¬ë°± í™•ë³´)
st.markdown("""
    <style>
    .main { background-color: #ffffff; }
    h1, h2, h3 { color: #003366; font-family: 'Arial', sans-serif; }
    .stMetric { background-color: #f8f9fa; padding: 15px; border-radius: 8px; border: 1px solid #e9ecef; }
    .stAlert { padding: 10px; border-radius: 5px; }
    /* í•˜ë‹¨ ì—¬ë°± í™•ë³´ë¥¼ ìœ„í•œ í´ë˜ìŠ¤ */
    .bottom-spacer { height: 300px; }
    </style>
""", unsafe_allow_html=True)

# -------------------------------------------------------------------
# ì„¸ì…˜ ìƒíƒœ(Session State) ì´ˆê¸°í™”
# -------------------------------------------------------------------
# ë¶„ì„ ê²°ê³¼ê°€ ìƒˆë¡œê³ ì¹¨(íƒ­ í´ë¦­ ë“±) ì‹œì—ë„ ì‚¬ë¼ì§€ì§€ ì•Šë„ë¡ ì €ì¥ì†Œë¥¼ ë§Œë“­ë‹ˆë‹¤.
if 'analysis_results' not in st.session_state:
    st.session_state.analysis_results = None

# -------------------------------------------------------------------
# í•¨ìˆ˜ ì •ì˜
# -------------------------------------------------------------------

def load_data(uploaded_files):
    """íŒŒì¼ ë¡œë“œ ë° ë³‘í•©"""
    all_dfs = []
    for uploaded_file in uploaded_files:
        try:
            if uploaded_file.name.endswith('.csv'):
                try:
                    df = pd.read_csv(uploaded_file, encoding='utf-8')
                except UnicodeDecodeError:
                    df = pd.read_csv(uploaded_file, encoding='cp949')
                all_dfs.append(df)
            elif uploaded_file.name.endswith('.xlsx'):
                df = pd.read_excel(uploaded_file)
                all_dfs.append(df)
        except Exception as e:
            st.error(f"íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜ ({uploaded_file.name}): {e}")
    
    if all_dfs:
        return pd.concat(all_dfs, ignore_index=True)
    return None

def clean_column_names(df):
    """ì»¬ëŸ¼ëª… íŠ¹ìˆ˜ë¬¸ì ì œê±° (XGBoost ë“± í˜¸í™˜ì„± í™•ë³´)"""
    df.columns = df.columns.str.strip()
    return df

def detect_target_column(df):
    """íƒ€ê²Ÿ ì»¬ëŸ¼(PCE) ìë™ ê°ì§€"""
    candidates = [c for c in df.columns if 'PCE' in c.upper()]
    if candidates:
        return candidates[0]
    return df.columns[-1] if not df.empty else None

def preprocess_data(df, target_column):
    """ì „ì²˜ë¦¬: íƒ€ê²Ÿ ë¶„ë¦¬, ê²°ì¸¡ì¹˜ ì œê±°, ì¸ì½”ë”©, í˜•ë³€í™˜"""
    
    # 1. íƒ€ê²Ÿê°’ ê²°ì¸¡ì¹˜ ì œê±°
    df_cleaned = df.dropna(subset=[target_column]).copy()
    
    if len(df_cleaned) == 0:
        return None, None, None, None

    # 2. ê²°ê³¼ ì§€í‘œ ì œê±° (Data Leakage ë°©ì§€)
    drop_keywords = ['PCE', 'Voc', 'Jsc', 'FF', 'Rs', 'Rsh', 'Scan', 'Sample', 'File', 'Unnamed']
    cols_to_drop = []
    for col in df_cleaned.columns:
        if col == target_column: continue
        for kw in drop_keywords:
            if kw in col:
                cols_to_drop.append(col)
                break
    
    X_raw = df_cleaned.drop(columns=cols_to_drop, errors='ignore')
    y = df_cleaned[target_column]
    
    # 3. MLB / One-Hot Encoding
    X_numeric = X_raw.select_dtypes(exclude=['object'])
    X_categorical = X_raw.select_dtypes(include=['object'])
    
    all_processed = [X_numeric]
    for col in X_categorical.columns:
        # 'A + B' í˜•íƒœ ë¶„ë¦¬
        binarized = X_categorical[col].fillna('').astype(str).str.get_dummies(sep=' + ')
        binarized = binarized.add_prefix(f"{col}_")
        all_processed.append(binarized)
        
    X_processed = pd.concat(all_processed, axis=1).fillna(0)
    
    # 4. íŠ¹ìˆ˜ë¬¸ì ì œê±° (ì»¬ëŸ¼ëª…)
    X_processed.columns = X_processed.columns.str.replace(r'[^\w\s]', '_', regex=True).str.replace(r'\s+', '_', regex=True)
    
    # 5. [ì¤‘ìš”] ëª¨ë“  ë°ì´í„°ë¥¼ floatí˜•ìœ¼ë¡œ ê°•ì œ ë³€í™˜ (ì—ëŸ¬ ë°©ì§€)
    try:
        X_processed = X_processed.astype(float)
    except ValueError:
        # ë³€í™˜ ì‹¤íŒ¨ ì‹œ (í˜¹ì‹œ ëª¨ë¥¼ ë¬¸ìì—´ ì”ì¬) ê°•ì œ ë³€í™˜
        for col in X_processed.columns:
            X_processed[col] = pd.to_numeric(X_processed[col], errors='coerce').fillna(0)

    return X_processed, y, df_cleaned, X_raw

# -------------------------------------------------------------------
# ë©”ì¸ UI
# -------------------------------------------------------------------

st.title("ğŸ§ª Perovskite AI Lab V5")
st.write("ì¬ë£Œ íƒìƒ‰ ë° ê³µì • ìµœì í™”ë¥¼ ìœ„í•œ ì§€ëŠ¥í˜• ë¶„ì„ í”Œë«í¼")
st.markdown("---")

# 1. ì‚¬ì´ë“œë°”: ë°ì´í„° ì—…ë¡œë“œ
with st.sidebar:
    st.header("ğŸ“‚ 1. Data Input")
    uploaded_files = st.file_uploader("CSV/Excel ì—…ë¡œë“œ", type=['csv', 'xlsx'], accept_multiple_files=True)
    
    st.markdown("---")
    
    # ê²°ê³¼ ì´ˆê¸°í™” ë²„íŠ¼
    if st.button("ğŸ”„ ê²°ê³¼ ì´ˆê¸°í™” (Reset)"):
        st.session_state.analysis_results = None
        st.rerun()

    st.caption("Developed based on recent PV ML studies (Nature Energy, 2024)")

if uploaded_files:
    raw_df = load_data(uploaded_files)
    
    if raw_df is not None:
        raw_df = clean_column_names(raw_df)
        st.write(f"âœ… **{len(raw_df)}**ê°œì˜ ìƒ˜í”Œ ë°ì´í„°ê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        with st.expander("ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°"):
            st.dataframe(raw_df.head())
        
        st.markdown("---")
        
        # ----------------------------------------------------------------
        # 2. ì‚¬ìš©ì ì„¤ì • (íƒ€ê²Ÿ & ëª¨ë¸ ì„ íƒ)
        # ----------------------------------------------------------------
        st.header("âš™ï¸ 2. Analysis Settings")
        
        col_set1, col_set2, col_set3 = st.columns(3)
        
        # Step 1: íƒ€ê²Ÿ ë³€ìˆ˜ ì„ íƒ
        with col_set1:
            default_target = detect_target_column(raw_df)
            try:
                default_idx = list(raw_df.columns).index(default_target) if default_target else 0
            except:
                default_idx = 0
                
            target_col = st.selectbox(
                "ëª©í‘œ íƒ€ê²Ÿ (Target Variable)", 
                options=raw_df.columns, 
                index=default_idx,
                help="ì˜ˆì¸¡í•˜ê³ ì í•˜ëŠ” ê°’ (ë³´í†µ íš¨ìœ¨ PCE)"
            )

        # Step 2: ëª¨ë¸ ì„ íƒ
        with col_set2:
            model_options = [
                "XGBoost (Recommended)",
                "Random Forest (Robust)",
                "Gaussian Process (Bayesian Opt.)"
            ]
            model_choice = st.selectbox(
                "ì‚¬ìš©í•  ML ëª¨ë¸", 
                options=model_options,
                help="ë°ì´í„°ê°€ ì ë‹¤ë©´ Gaussian Processë‚˜ Random Forestë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤."
            )
        
        # Step 3: í…ŒìŠ¤íŠ¸ ë¹„ìœ¨
        with col_set3:
            test_ratio = st.slider("í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¹„ìœ¨", 0.1, 0.5, 0.2, 0.05)

        # ê²½ê³  ë° ê°€ì´ë“œ ë©”ì‹œì§€
        data_len = len(raw_df)
        if data_len < 20:
            st.warning(f"âš ï¸ ë°ì´í„°ê°€ **{data_len}ê°œ**ë¡œ ë§¤ìš° ì ìŠµë‹ˆë‹¤.")
            if "XGBoost" in model_choice:
                st.error("ğŸ›‘ XGBoostëŠ” ë°ì´í„°ê°€ ë„ˆë¬´ ì ì„ ë•Œ(20ê°œ ë¯¸ë§Œ) ì‘ë™í•˜ì§€ ì•Šê±°ë‚˜ ê³¼ì í•©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. **Gaussian Process** ë˜ëŠ” **Random Forest**ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
            else:
                st.info("ğŸ’¡ ì ì€ ë°ì´í„°ì…‹(Small Data)ì— ê°•í•œ ëª¨ë¸ì„ ì„ íƒí•˜ì…¨êµ°ìš”. ë¶„ì„ì„ ì§„í–‰í•©ë‹ˆë‹¤.")

        # ----------------------------------------------------------------
        # 3. ë¶„ì„ ì‹¤í–‰ (Session State ì €ì¥ ë¡œì§ ì ìš©)
        # ----------------------------------------------------------------
        st.markdown("<br>", unsafe_allow_html=True)
        
        # ë¶„ì„ ë²„íŠ¼
        if st.button("ğŸš€ AI ë¶„ì„ ë° ìµœì í™” ì‹œì‘ (Run Analysis)", type="primary"):
            
            with st.spinner(f"ë°ì´í„° ì „ì²˜ë¦¬ ë° {model_choice.split()[0]} ìµœì í™” ì¤‘..."):
                try:
                    # ì „ì²˜ë¦¬
                    X, y, df_clean, X_raw_origin = preprocess_data(raw_df, target_col)
                    
                    if X is None:
                        st.error("ì „ì²˜ë¦¬ ì‹¤íŒ¨: íƒ€ê²Ÿ ì»¬ëŸ¼ì— ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        # ë°ì´í„° ë¶„í• 
                        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_ratio, random_state=42)
                        
                        # ëª¨ë¸ ì´ˆê¸°í™” ë° í•™ìŠµ
                        model = None
                        is_tree_model = False
                        
                        # -----------------------
                        # A. XGBoost
                        # -----------------------
                        if "XGBoost" in model_choice:
                            is_tree_model = True
                            xgb_reg = xgb.XGBRegressor(objective='reg:squarederror', n_jobs=-1, random_state=42)
                            param_grid = {
                                'n_estimators': [100, 200] if len(X) < 50 else [100, 300, 500],
                                'max_depth': [3, 5],
                                'learning_rate': [0.05, 0.1]
                            }
                            search = GridSearchCV(xgb_reg, param_grid, cv=3, scoring='neg_mean_absolute_error')
                            search.fit(X_train, y_train)
                            model = search.best_estimator_

                        # -----------------------
                        # B. Random Forest
                        # -----------------------
                        elif "Random Forest" in model_choice:
                            is_tree_model = True
                            rf_reg = RandomForestRegressor(random_state=42, n_jobs=-1)
                            param_grid = {
                                'n_estimators': [100, 200],
                                'max_depth': [None, 10],
                                'min_samples_leaf': [1, 2]
                            }
                            search = GridSearchCV(rf_reg, param_grid, cv=3, scoring='neg_mean_absolute_error')
                            search.fit(X_train, y_train)
                            model = search.best_estimator_

                        # -----------------------
                        # C. Gaussian Process
                        # -----------------------
                        elif "Gaussian Process" in model_choice:
                            # ë°ì´í„° ìŠ¤ì¼€ì¼ë§
                            scaler_X = StandardScaler()
                            X_train_scaled = scaler_X.fit_transform(X_train)
                            X_test_scaled = scaler_X.transform(X_test)
                            
                            kernel = 1.0 * RBF(length_scale=1.0) + WhiteKernel(noise_level=1.0)
                            gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=5, random_state=42)
                            gp.fit(X_train_scaled, y_train)
                            model = gp
                            
                            # GPìš© ì»¤ìŠ¤í…€ predict í•¨ìˆ˜ ì €ì¥
                            model.custom_predict = lambda X_in: gp.predict(scaler_X.transform(X_in), return_std=False)
                            model.custom_predict_std = lambda X_in: gp.predict(scaler_X.transform(X_in), return_std=True)

                        # ì˜ˆì¸¡ ë° í‰ê°€
                        if "Gaussian Process" in model_choice:
                            y_pred, y_std = model.custom_predict_std(X_test)
                        else:
                            y_pred = model.predict(X_test)
                            y_std = None
                        
                        r2 = r2_score(y_test, y_pred)
                        mae = mean_absolute_error(y_test, y_pred)

                        # ê²°ê³¼ ì„¸ì…˜ ì €ì¥
                        st.session_state.analysis_results = {
                            "model_choice": model_choice,
                            "r2": r2,
                            "mae": mae,
                            "y_test": y_test,
                            "y_pred": y_pred,
                            "y_std": y_std,
                            "target_col": target_col,
                            "model": model,
                            "X_train": X_train,
                            "X_test": X_test,
                            "X": X,
                            "y": y,
                            "X_raw_origin": X_raw_origin,
                            "df_clean": df_clean,
                            "is_tree_model": is_tree_model
                        }
                        
                except Exception as e:
                    st.error(f"ëª¨ë¸ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

        # ----------------------------------------------------------------
        # 4. ê²°ê³¼ ë¦¬í¬íŠ¸ (ì €ì¥ëœ ì„¸ì…˜ ë°ì´í„°ë¡œ í‘œì‹œ)
        # ----------------------------------------------------------------
        if st.session_state.analysis_results is not None:
            res = st.session_state.analysis_results
            
            st.success("âœ… ë¶„ì„ ì™„ë£Œ!")
            
            # Tab êµ¬ì„±
            tab1, tab2, tab3 = st.tabs(["ğŸ“Š ì„±ëŠ¥ í‰ê°€", "ğŸ” ì¤‘ìš”ë„ ë¶„ì„ (XAI)", "ğŸ’¡ ìµœì í™” ì œì•ˆ"])
            
            with tab1:
                c1, c2 = st.columns(2)
                c1.metric("RÂ² Score (ì •í™•ë„)", f"{res['r2']:.4f}")
                c2.metric("MAE (í‰ê·  ì˜¤ì°¨)", f"{res['mae']:.4f}")
                
                fig, ax = plt.subplots(figsize=(6, 5))
                ax.scatter(res['y_test'], res['y_pred'], alpha=0.7, edgecolors='k', label='Data')
                ax.plot([res['y'].min(), res['y'].max()], [res['y'].min(), res['y'].max()], 'r--', lw=2, label='Ideal')
                if res['y_std'] is not None:
                    ax.errorbar(res['y_test'], res['y_pred'], yerr=res['y_std'], fmt='none', alpha=0.2, ecolor='gray', label='Uncertainty')
                
                ax.set_xlabel(f"Actual {res['target_col']}")
                ax.set_ylabel(f"Predicted {res['target_col']}")
                ax.set_title(f"{res['model_choice'].split()[0]} Regression Result")
                ax.legend()
                st.pyplot(fig)

            with tab2:
                st.subheader("Feature Analysis")
                importances = None
                
                if res['is_tree_model']:
                    st.write("**SHAP (SHapley Additive exPlanations)** ë¶„ì„ ê²°ê³¼")
                    try:
                        explainer = shap.Explainer(res['model'], res['X_train'])
                        shap_values = explainer(res['X_test'])
                        
                        fig_shap, ax_shap = plt.subplots()
                        shap.summary_plot(shap_values, res['X_test'], show=False)
                        st.pyplot(fig_shap)
                        
                        # ì¤‘ìš”ë„ ì¶”ì¶œ
                        importances = np.abs(shap_values.values).mean(axis=0)
                    except Exception as e:
                        st.warning(f"SHAP ê³„ì‚° ì¤‘ ê²½ê³ : {e}")
                        # Fallback to feature importances
                        importances = res['model'].feature_importances_
                else:
                    st.info("Gaussian ProcessëŠ” SHAP ëŒ€ì‹  ìƒê´€ê³„ìˆ˜(Correlation)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¤‘ìš”ë„ë¥¼ ì¶”ì •í•©ë‹ˆë‹¤.")
                    # ê°„ë‹¨í•œ ìƒê´€ê³„ìˆ˜ íˆíŠ¸ë§µ
                    corr = res['X'].copy()
                    corr['Target'] = res['y']
                    corr_matrix = corr.corr()[['Target']].sort_values(by='Target', key=abs, ascending=False).head(10)
                    st.dataframe(corr_matrix.style.background_gradient(cmap='coolwarm'))
                    importances = np.abs(corr.corr()[res['target_col']].drop(res['target_col']).values)
                    # ì¤‘ìš”ë„ ë°°ì—´ í¬ê¸° ë§ì¶¤ (X ì»¬ëŸ¼ ìˆœì„œëŒ€ë¡œ ì •ë ¬ í•„ìš” - ìœ„ ì½”ë“œëŠ” ê·¼ì‚¬ì¹˜)
                    # ì •í™•í•œ ë§¤í•‘ì„ ìœ„í•´ ë‹¤ì‹œ ê³„ì‚°
                    full_corr = corr.corr()[res['target_col']].drop(res['target_col'])
                    importances = np.abs(full_corr[res['X'].columns].values)

            with tab3:
                st.subheader("ì‹¤í—˜ ì¡°ê±´ ìµœì í™” ì œì•ˆ")
                best_idx = res['y'].idxmax()
                st.success(f"í˜„ì¬ ìµœê³  ì„±ëŠ¥: **{res['y'].max():.4f}** (Sample ID: {best_idx})")
                
                # ì¤‘ìš” ë³€ìˆ˜ Top 5
                feat_imp_df = pd.DataFrame({'Feature': res['X'].columns, 'Imp': list(importances)})
                top_feats = feat_imp_df.sort_values('Imp', ascending=False).head(5)['Feature'].tolist()
                
                best_recipe = res['df_clean'].loc[best_idx]
                suggestions = []
                for feat in top_feats:
                    # ì›ë³¸ ì»¬ëŸ¼ ì°¾ê¸°
                    orig = feat
                    for raw_c in res['X_raw_origin'].columns:
                        # ì „ì²˜ë¦¬ëœ ì´ë¦„ê³¼ ë§¤ì¹­ë˜ëŠ”ì§€ í™•ì¸
                        if re.sub(r'[^\w]', '_', str(raw_c)) in feat:
                            orig = raw_c
                            break
                    
                    val = best_recipe.get(orig, best_recipe.get(feat, "N/A"))
                    suggestions.append({
                        "ì¤‘ìš” ë³€ìˆ˜": feat,
                        "í˜„ì¬ ìµœê³ ê°’": val,
                        "ì œì•ˆ": "ì´ ë³€ìˆ˜ì˜ ì£¼ë³€ ê°’ì„ íƒìƒ‰(Exploration) í•˜ì„¸ìš”."
                    })
                
                st.table(pd.DataFrame(suggestions))
            
            # í•˜ë‹¨ ì—¬ë°± ì¶”ê°€ (ìŠ¤í¬ë¡¤ ë¬¸ì œ í•´ê²°)
            st.markdown('<div class="bottom-spacer"></div>', unsafe_allow_html=True)

else:
    st.info("ğŸ‘ˆ ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ë°ì´í„° íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
