import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import cv2
from PIL import Image
import io
import os
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_absolute_error
from skimage import feature, measurement, segmentation
from scipy import ndimage

# --- [ì„¤ì •] í˜ì´ì§€ í™˜ê²½ ì„¤ì • ---
st.set_page_config(page_title="SolarCell Data Hub", layout="wide")

# --- [ì‚¬ì´ë“œë°”] ê³µí†µ ì œì–´ ì˜ì—­ ---
st.sidebar.header("ğŸ“ Global Data Center")
main_csv = st.sidebar.file_uploader("1. ML ë°ì´í„°ì…‹ ì—…ë¡œë“œ (CSV/XLSX)", type=["csv", "xlsx"]) #

# --- [ê¸°ëŠ¥ í•¨ìˆ˜: ML ë¶„ì„] ---
def run_rf_analysis(df):
    """ ê¸°ë°˜ ë¶„ì„"""
    target_col = 'PCE (%)'
    df_ml = df.dropna(subset=[target_col])
    
    # ê²°ê³¼ê°’ ì œì™¸ (Data Leakage ë°©ì§€)
    X = df_ml.drop(columns=[
        'PCE (%)', 'Voc (V)', 'Jsc (mA/cm2)', 'FF (%)', 'Rs (Î©Â·cmÂ²)', 'Rsh (Î©Â·cmÂ²)',
        'Sample', 'File', 'Scan Direction', 'Operator', 'Structure'
    ], errors='ignore')
    y = df_ml[target_col]

    # ë²”ì£¼í˜• ë³€ìˆ˜ ì²˜ë¦¬
    X_numeric = X.select_dtypes(exclude=['object'])
    X_categorical = X.select_dtypes(include=['object'])
    processed_parts = [X_numeric]
    for col in X_categorical.columns:
        binarized = X_categorical[col].fillna('').str.get_dummies(sep=' + ')
        binarized = binarized.add_prefix(f"{col}_")
        processed_parts.append(binarized)

    X_processed = pd.concat(processed_parts, axis=1).fillna(0)
    X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)
    
    model = RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1)
    model.fit(X_train, y_train)
    return model, X_test, y_test, X_processed

# --- [ê¸°ëŠ¥ í•¨ìˆ˜: SEM ê²°ì •ë¦½ ë¶„ì„] ---
def analyze_grain_size(img_array, bar_nm, bar_pixel_width):
    gray = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)
    nm_per_pixel = bar_nm / bar_pixel_width
    denoised = cv2.fastNlMeansDenoising(gray, None, 10, 7, 21)
    thresh = cv2.adaptiveThreshold(denoised, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)
    labels = measurement.label(thresh)
    props = measurement.regionprops(labels)
    diameters = [p.equivalent_diameter * nm_per_pixel for p in props if p.area > 50]
    return diameters, thresh

# --- [ë©”ì¸ íƒ­ êµ¬ì„±] ---
# CSV ì—…ë¡œë“œ ì—¬ë¶€ì™€ ìƒê´€ì—†ì´ íƒ­ì´ í•­ìƒ ë³´ì´ë„ë¡ ë°°ì¹˜
tab1, tab2, tab3, tab4 = st.tabs([
    "ğŸ“Š J-V Dashboard", 
    "ğŸ“ˆ XRD & PL Analysis", 
    "ğŸ”¬ SEM Grain Analysis", 
    "ğŸ¤– Machine Learning"
])

# íƒ­ 1: J-V ë°ì´í„° ëŒ€ì‹œë³´ë“œ
with tab1:
    if main_csv:
        df = pd.read_csv(main_csv) if main_csv.name.endswith('.csv') else pd.read_excel(main_csv)
        st.header("Master Database Overview")
        c1, c2, c3 = st.columns(3)
        c1.metric("Devices", len(df)) #
        c2.metric("Best PCE (%)", df['PCE (%)'].max())
        c3.metric("Avg Voc (V)", f"{df['Voc (V)'].mean():.3f}")
        st.dataframe(df, use_container_width=True)
    else:
        st.info("ì‚¬ì´ë“œë°”ì—ì„œ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ë°ì´í„° ìš”ì•½ì´ í‘œì‹œë©ë‹ˆë‹¤.")

# íƒ­ 2: XRD & PL (í…ìŠ¤íŠ¸ íŒŒì¼ ì—…ë¡œë“œ)
with tab2:
    st.header("XRD & PL Spectrum Plotter")
    st.markdown("`.txt` ë˜ëŠ” `.csv` í˜•íƒœì˜ ì›ë³¸ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    
    char_files = st.file_uploader("XRD/PL ë°ì´í„° íŒŒì¼ ì—…ë¡œë“œ (Multi-select ê°€ëŠ¥)", type=["txt", "csv"], accept_multiple_files=True)
    
    if char_files:
        for f in char_files:
            try:
                # ë°ì´í„° íŒŒì‹± (1ì—´: X, 2ì—´: Intensity ê°€ì •)
                char_df = pd.read_csv(f, sep=r'\s+', header=None, names=['X', 'Intensity'])
                fig = px.line(char_df, x='X', y='Intensity', title=f"File: {f.name}")
                st.plotly_chart(fig, use_container_width=True)
            except Exception as e:
                st.error(f"{f.name} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# íƒ­ 3: SEM ì´ë¯¸ì§€ ë¶„ì„
with tab3:
    st.header("SEM Grain Size Analyzer")
    sem_file = st.file_uploader("SEM ì´ë¯¸ì§€ íŒŒì¼ ì—…ë¡œë“œ (JPG, PNG, TIF)", type=["jpg", "png", "tif"])
    
    if sem_file:
        c_img, c_res = st.columns(2)
        img = Image.open(sem_file)
        img_array = np.array(img)
        c_img.image(img, caption="Original SEM Image", use_container_width=True)
        
        # ë¶„ì„ ì„¤ì • (ì´ë¯¸ì§€ í•˜ë‹¨ ë°°ìœ¨ë°” ê¸°ì¤€)
        st.divider()
        col_set1, col_set2 = st.columns(2)
        bar_nm = col_set1.number_input("Scale Bar ì‹¤ì œ ê¸¸ì´ (nm)", value=500, step=100)
        bar_px = col_set2.number_input("Scale Barì˜ í”½ì…€ ê¸¸ì´ (ì¸¡ì •ê°’)", value=100, step=1)
        
        if st.button("ğŸš€ ìë™ ê²°ì •ë¦½ ë¶„ì„ ì‹¤í–‰"):
            diameters, processed_img = analyze_grain_size(img_array, bar_nm, bar_px)
            c_res.image(processed_img, caption="Detected Grain Boundaries", use_container_width=True)
            
            # ë¶„ì„ ê²°ê³¼ í…ìŠ¤íŠ¸í™”
            st.subheader("ğŸ“ SEM ë¶„ì„ ë¦¬í¬íŠ¸")
            res1, res2, res3 = st.columns(3)
            res1.write(f"**ê²€ì¶œëœ ê·¸ë ˆì¸ ìˆ˜:** {len(diameters)} ê°œ")
            res2.write(f"**í‰ê·  í¬ê¸°:** {np.mean(diameters):.2f} nm")
            res3.write(f"**í‘œì¤€ í¸ì°¨:** {np.std(diameters):.2f} nm")
            
            # ë¶„í¬ë„ ê·¸ë˜í”„
            fig_hist = px.histogram(diameters, nbins=20, title="Grain Size Distribution",
                                    labels={'value': 'Size (nm)'}, color_discrete_sequence=['indianred'])
            st.plotly_chart(fig_hist, use_container_width=True)

# íƒ­ 4: ë¨¸ì‹ ëŸ¬ë‹ ë¶„ì„
with tab4:
    st.header("AI-Driven Research Insight")
    if main_csv:
        if st.button("Run Random Forest Prediction"):
            model, X_test, y_test, X_processed = run_rf_analysis(df)
            y_pred = model.predict(X_test)
            
            st.success(f"ëª¨ë¸ í•™ìŠµ ì™„ë£Œ! RÂ²: {r2_score(y_test, y_pred):.3f}")
            
            # ì¤‘ìš” ë³€ìˆ˜ ì‹œê°í™”
            importances = pd.DataFrame({'Variable': X_processed.columns, 'Importance': model.feature_importances_})
            importances = importances.sort_values(by='Importance', ascending=False).head(15)
            fig_imp = px.bar(importances, x='Importance', y='Variable', orientation='h', 
                             title="Top 15 Critical Variables", color='Importance')
            st.plotly_chart(fig_imp, use_container_width=True)
    else:
        st.warning("ë¨¸ì‹ ëŸ¬ë‹ ë¶„ì„ì„ ìœ„í•´ ì‚¬ì´ë“œë°”ì—ì„œ ë©”ì¸ CSV íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
