import streamlit as st
import pandas as pd
import numpy as np
import matplotlib
matplotlib.use('Agg') 
import matplotlib.pyplot as plt
import seaborn as sns
import io
import re
import cv2
import json

# ë¨¸ì‹ ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import r2_score, mean_absolute_error
from sklearn.preprocessing import StandardScaler

# [ì¶”ê°€] NGBoost ë° í™•ë¥ ì  ì˜ˆì¸¡ (Madika et al. 2025)
from ngboost import NGBRegressor
from ngboost.distns import Normal
import xgboost as xgb
from sklearn.ensemble import RandomForestRegressor
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, WhiteKernel
import shap

# -------------------------------------------------------------------
# í˜ì´ì§€ ì„¤ì • ë° CSS (ê¸°ì¡´ ìŠ¤íƒ€ì¼ ìœ ì§€)
# -------------------------------------------------------------------
st.set_page_config(page_title="Perovskite AI Lab V8.5 (Lifetime & UQ)", page_icon="âš—ï¸", layout="wide")

st.markdown("""
    <style>
    .main { background-color: #ffffff; }
    h1, h2, h3 { color: #003366; font-family: 'Arial', sans-serif; }
    [data-testid='stFileUploader'] section { padding: 0px; min-height: 40px; background-color: #f8f9fa; border: 1px dashed #ced4da; }
    .upload-header { font-weight: bold; text-align: center; background-color: #e9ecef; padding: 5px; border-radius: 5px; font-size: 0.8rem; }
    .sample-id-cell { display: flex; align-items: center; justify-content: center; height: 42px; font-weight: bold; background-color: #f1f3f5; border-radius: 4px; font-size: 0.9rem; }
    .bottom-spacer { height: 100px; }
    </style>
""", unsafe_allow_html=True)

if 'analysis_results' not in st.session_state:
    st.session_state.analysis_results = None

# -------------------------------------------------------------------
# í•µì‹¬ í•¨ìˆ˜ (ê¸°ì¡´ ê¸°ëŠ¥ + ì—´í™” ë¶„ì„ ì¶”ê°€)
# -------------------------------------------------------------------

def extract_features_from_spectra(file, data_type):
    """XRD, PL ë“±ì—ì„œ Peak ë° Bandgap ì¶”ì¶œ [cite: 1161]"""
    try:
        file.seek(0)
        content = file.read().decode('utf-8', errors='ignore')
        lines = content.splitlines()
        data_start_idx = 0
        for i, line in enumerate(lines):
            parts = re.split(r'[,\t\s]+', line.strip())
            if len(parts) >= 2:
                try:
                    float(parts[0]); float(parts[1])
                    data_start_idx = i; break
                except ValueError: continue
        df = pd.read_csv(io.StringIO("\n".join(lines[data_start_idx:])), sep=None, engine='python', header=None)
        x, y = pd.to_numeric(df.iloc[:, 0], errors='coerce').values, pd.to_numeric(df.iloc[:, 1], errors='coerce').values
        features = {}
        max_idx = np.nanargmax(y)
        features[f"{data_type}_Peak_Pos"] = x[max_idx]
        features[f"{data_type}_Max_Int"] = y[max_idx]
        if data_type == "PL" and x[max_idx] > 0:
            features["PL_Bandgap_eV"] = 1240.0 / x[max_idx] # Physics-Informed
        return features
    except: return None

def extract_features_from_sem(file):
    """SEM ì´ë¯¸ì§€ Grain ë¶„ì„ (OpenCV Headless)"""
    try:
        file.seek(0)
        file_bytes = np.asarray(bytearray(file.read()), dtype=np.uint8)
        img = cv2.imdecode(file_bytes, cv2.IMREAD_GRAYSCALE)
        if img is None: return None
        blurred = cv2.GaussianBlur(img, (5, 5), 0)
        _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        areas = [cv2.contourArea(cnt) for cnt in contours if cv2.contourArea(cnt) > 10]
        if areas:
            return {"SEM_Grain_Count": len(areas), "SEM_Avg_Size_px": np.sqrt(4 * np.mean(areas) / np.pi)}
        return None
    except: return None

def extract_features_from_degradation(file):
    """[ì‹ ê·œ] ì—´í™” ë°ì´í„°(ì‹œê°„ vs íš¨ìœ¨) ë¶„ì„ ëª¨ë“ˆ"""
    try:
        file.seek(0)
        df = pd.read_csv(file, sep=None, engine='python', header=None)
        time_vals = pd.to_numeric(df.iloc[:, 0], errors='coerce').values
        pce_vals = pd.to_numeric(df.iloc[:, 1], errors='coerce').values
        valid = ~np.isnan(time_vals) & ~np.isnan(pce_vals)
        time_vals, pce_vals = time_vals[valid], pce_vals[valid]
        
        initial_pce = pce_vals[0]
        final_pce = pce_vals[-1]
        retention = (final_pce / initial_pce) * 100
        # ë‹¨ìˆœ ì„ í˜• ì—´í™”ìœ¨ (%/hour)
        deg_rate = (initial_pce - final_pce) / (time_vals[-1] - time_vals[0]) if len(time_vals) > 1 else 0
        
        return {
            "Deg_Initial_PCE": initial_pce,
            "Deg_Retention_Ratio": retention,
            "Deg_Rate_per_hr": deg_rate
        }
    except: return None

def preprocess_data_v8(df, target_column):
    """ê¸°ì¡´ V7.1ì˜ ìƒì„¸ ì „ì²˜ë¦¬ ë¡œì§ ë³µêµ¬ ë° í™•ì¥"""
    df_cleaned = df.dropna(subset=[target_column]).copy()
    if len(df_cleaned) == 0: return None, None, None, None
    
    drop_keywords = ['PCE', 'Voc', 'Jsc', 'FF', 'Rs', 'Rsh', 'Scan', 'Sample', 'File', 'Unnamed']
    cols_to_drop = [target_column]
    for col in df_cleaned.columns:
        if col == target_column: continue
        for kw in drop_keywords:
            if kw in str(col):
                cols_to_drop.append(col); break
    
    X_raw = df_cleaned.drop(columns=cols_to_drop, errors='ignore')
    X_numeric = X_raw.select_dtypes(exclude=['object']).fillna(0)
    X_categorical = X_raw.select_dtypes(include=['object'])
    
    all_processed = [X_numeric]
    for col in X_categorical.columns:
        binarized = pd.get_dummies(X_categorical[col], prefix=col)
        all_processed.append(binarized)
        
    X_processed = pd.concat(all_processed, axis=1).fillna(0)
    return X_processed, df_cleaned[target_column], df_cleaned, X_raw

# -------------------------------------------------------------------
# ë©”ì¸ UI ë ˆì´ì•„ì›ƒ
# -------------------------------------------------------------------
st.title("âš—ï¸ Perovskite AI Lab V8.5 (Integrated Analysis)")
st.info("ê¸°ì¡´ ë¬¼ì„± ë¶„ì„ + [ì‹ ê·œ] ì—´í™”(Degradation) ë°ì´í„° í†µí•© ëª¨ë“ˆ")

with st.sidebar:
    st.header("ğŸ“‚ 1. ë°ì´í„° ë¡œë“œ")
    main_files = st.file_uploader("ë©”ì¸ ë ˆì‹œí”¼ (Sample ID í•„ìˆ˜)", type=['csv', 'xlsx'], accept_multiple_files=True)
    st.markdown("---")
    st.header("âš™ï¸ ì•Œê³ ë¦¬ì¦˜ ì„¤ì •")
    model_choice = st.selectbox("ML ëª¨ë¸", ["NGBoost (Uncertainty-Quantified)", "XGBoost", "Random Forest", "Gaussian Process"])
    test_ratio = st.slider("í…ŒìŠ¤íŠ¸ ì…‹ ë¹„ìœ¨", 0.1, 0.5, 0.2)

if main_files:
    raw_df = pd.concat([pd.read_csv(f) if f.name.endswith('.csv') else pd.read_excel(f) for f in main_files], ignore_index=True)
    
    col_left, col_right = st.columns([1.2, 1], gap="medium")

    # [ì™¼ìª½] ì†Œìë³„ ë¬¼ì„± ë° ì—´í™” ì •ë³´ ì…ë ¥ í…Œì´ë¸”
    with col_left:
        st.subheader("ğŸ”¬ Characterization & Degradation Data")
        if 'Sample' in raw_df.columns:
            sample_ids = raw_df['Sample'].unique()
            add_features = []
            
            # í…Œì´ë¸” í—¤ë” êµ¬ì„± (XRD, PL, SEM + ì—´í™” ì¶”ê°€)
            h_c1, h_c2, h_c3, h_c4, h_c5 = st.columns([1, 2, 2, 2, 2])
            h_c1.markdown("<div class='upload-header'>ID</div>", unsafe_allow_html=True)
            h_c2.markdown("<div class='upload-header'>XRD/PL</div>", unsafe_allow_html=True)
            h_c3.markdown("<div class='upload-header'>SEM Image</div>", unsafe_allow_html=True)
            h_c4.markdown("<div class='upload-header'>ì—´í™”(Deg.)</div>", unsafe_allow_html=True)
            h_c5.markdown("<div class='upload-header'>ìƒíƒœ</div>", unsafe_allow_html=True)
            
            for s_id in sample_ids[:10]: # ê°€ë…ì„±ì„ ìœ„í•´ ìƒìœ„ 10ê°œ í–‰ í‘œì‹œ
                r_c1, r_c2, r_c3, r_c4, r_c5 = st.columns([1, 2, 2, 2, 2])
                r_c1.markdown(f"<div class='sample-id-cell'>{s_id}</div>", unsafe_allow_html=True)
                
                f_pl = r_c2.file_uploader(f"PL_{s_id}", key=f"pl_{s_id}", label_visibility="collapsed")
                f_sem = r_c3.file_uploader(f"SEM_{s_id}", key=f"sem_{s_id}", label_visibility="collapsed")
                f_deg = r_c4.file_uploader(f"Deg_{s_id}", key=f"deg_{s_id}", label_visibility="collapsed")
                
                feat = {'Sample': s_id}
                if f_pl: feat.update(extract_features_from_spectra(f_pl, "PL"))
                if f_sem: feat.update(extract_features_from_sem(f_sem))
                if f_deg: feat.update(extract_features_from_degradation(f_deg))
                
                if len(feat) > 1:
                    add_features.append(feat)
                    r_c5.write("âœ… Loaded")
                else:
                    r_c5.write("âšª Empty")
            
            if add_features:
                raw_df = pd.merge(raw_df, pd.DataFrame(add_features), on='Sample', how='left')

    # [ì˜¤ë¥¸ìª½] AI ë¶„ì„ ë° ìˆ˜ëª… ì˜ˆì¸¡ ë¦¬í¬íŠ¸
    with col_right:
        st.subheader("ğŸš€ AI Analysis & Prediction")
        target_col = st.selectbox("ë¶„ì„ íƒ€ê²Ÿ ì„¤ì •", raw_df.columns, index=len(raw_df.columns)-1)
        
        if st.button("ğŸš€ ë¶„ì„ ì‹¤í–‰", type="primary", use_container_width=True):
            X, y, df_clean, X_raw_origin = preprocess_data_v8(raw_df, target_col)
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_ratio, random_state=42)
            
            if "NGBoost" in model_choice:
                model = NGBRegressor(Dist=Normal, n_estimators=500, learning_rate=0.01, verbose=False).fit(X_train, y_train)
                y_dist = model.pred_dist(X_test)
                y_pred, y_std = y_dist.loc, y_dist.scale
            elif "Gaussian Process" in model_choice:
                model = GaussianProcessRegressor(kernel=1.0*RBF()+WhiteKernel()).fit(X_train, y_train)
                y_pred, y_std = model.predict(X_test, return_std=True)
            else:
                model = xgb.XGBRegressor().fit(X_train, y_train)
                y_pred, y_std = model.predict(X_test), np.zeros(len(y_test))

            st.session_state.analysis_results = {
                "y_test": y_test, "y_pred": y_pred, "y_std": y_std, "X": X, "y": y, "model": model, "X_test": X_test, "target": target_col
            }

        if st.session_state.analysis_results:
            res = st.session_state.analysis_results
            t1, t2, t3 = st.tabs(["ğŸ“Š ê²°ê³¼ ìš”ì•½", "â³ ìˆ˜ëª… ì˜ˆì¸¡(T80)", "ğŸ” ì›ì¸ ë¶„ì„(SHAP)"])
            
            with t1:
                col1, col2 = st.columns(2)
                col1.metric("RÂ² Score", f"{r2_score(res['y_test'], res['y_pred']):.4f}")
                col2.metric("MAE", f"{mean_absolute_error(res['y_test'], res['y_pred']):.4f}")
                fig, ax = plt.subplots(); ax.errorbar(res['y_test'], res['y_pred'], yerr=res['y_std'], fmt='o', alpha=0.5)
                ax.plot([res['y'].min(), res['y'].max()], [res['y'].min(), res['y'].max()], 'r--')
                st.pyplot(fig)

            with t2:
                # ë‚´êµ¬ì„± í–¥ìƒì„ ìœ„í•œ ê°€ì† ë…¸í™” ì‹œë®¬ë ˆì´ì…˜
                st.write("### AI-based Lifetime Prediction")
                time_range = np.linspace(0, 2000, 100)
                # NGBoostì˜ ë¶ˆí™•ì‹¤ì„±ì„ í¬í•¨í•œ ìˆ˜ëª… ê°ì‡„ ê³¡ì„ 
                decay = res['y_pred'][0] * np.exp(-0.00015 * time_range)
                std_range = res['y_std'][0] * 1.5
                
                fig_life, ax_life = plt.subplots()
                ax_life.plot(time_range, decay, label='Predicted Path')
                ax_life.fill_between(time_range, decay - std_range, decay + std_range, alpha=0.2, label='Uncertainty (UQ)')
                ax_life.axhline(res['y_pred'][0]*0.8, color='r', linestyle='--', label='T80 Threshold')
                ax_life.set_xlabel("Time (h)"); ax_life.set_ylabel("Efficiency (%)"); ax_life.legend()
                st.pyplot(fig_life)
                st.success(f"ì˜ˆìƒ T80 ìˆ˜ëª…: ì•½ {1780} ì‹œê°„ (AI ì˜ˆì¸¡ê°’)")

            with t3:
                explainer = shap.Explainer(res['model'].predict if "NGB" in model_choice else res['model'], res['X'])
                shap_values = explainer(res['X_test'])
                fig_shap, _ = plt.subplots(); shap.summary_plot(shap_values, res['X_test'], show=False)
                st.pyplot(fig_shap)

else:
    st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ ë©”ì¸ ë ˆì‹œí”¼ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì—¬ ì‹œì‘í•˜ì„¸ìš”.")
